{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import typing as T\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import cv2\n",
    "import yaml\n",
    "import requests\n",
    "import torch\n",
    "import scipy\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from xarray import DataArray\n",
    "from tqdm.auto import tqdm\n",
    "import io\n",
    "from PIL import Image\n",
    "from bioimageio_chatbot.image_processor import *\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from random import choice\n",
    "import randomname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the training data and pick representatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/540 [00:00<00:42, 12.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding input images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 540/540 [00:40<00:00, 13.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded database includes 540 vectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Safety Counter Progress:   3%|▎         | 1607/54000 [04:04<2:13:04,  6.56it/s]\n"
     ]
    }
   ],
   "source": [
    "cellpose_train_dir = \"/Users/gkreder/Downloads/train\"\n",
    "cellpose_train_images = [os.path.join(cellpose_train_dir, x) for x in os.listdir(cellpose_train_dir) if x.endswith(\"_img.png\")]\n",
    "representative_images = get_representative_images(cellpose_train_images, verbose = True, threshold_distance=0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"/Users/gkreder/Downloads/cellpose_train-set_representatives\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "for fname in representative_images:\n",
    "    os.system(f\"cp {fname} {out_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 35 representatives images are currently stored in the gdrive folder \"cellpose_train-set_representatives\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-12-08 09:32:21.453\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mschema_agents.config\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m44\u001b[0m - \u001b[1mConfig loading done.\u001b[0m\n",
      "\u001b[32m2023-12-08 09:32:21.454\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mschema_agents.config\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m55\u001b[0m - \u001b[1mSet OPENAI_API_BASE in case of network issues\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "db_path = '../tmp/image_db/'\n",
    "image_processor = ImageProcessor()\n",
    "db = get_torch_db(db_path, image_processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entry[0] = result of get_torch_image. Results of get_model_torch_images()\n",
    "# entry[1] = embedded image (in numpy array format). Result of image_process.embed_image\n",
    "# entry[2] = rdf_dict (so need keys that match the nickname and axes at least)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellpose_rep_dir = '/Users/gkreder/Downloads/cellpose_train-set_representatives/'\n",
    "cellpose_image_paths = [os.path.join(cellpose_rep_dir, x) for x in os.listdir(cellpose_rep_dir) if not x.startswith(\".\")]\n",
    "for fname_abs in cellpose_image_paths:\n",
    "    fname = os.path.basename(fname_abs)\n",
    "    break\n",
    "# get_model_torch_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'straight-puffin'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_zoo_names = [x[-1]['config']['bioimageio']['nickname'] for x in db]\n",
    "rname = model_zoo_names[0]\n",
    "while rname in model_zoo_names:\n",
    "    rname = randomname.get_name(noun=(\"birds\", \"fish\"))\n",
    "rname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'straight-puffin_cellpose-435'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cps = f\"cellpose-{os.path.splitext(fname)[0].replace('_img', '')}\"\n",
    "nickname = f\"{rname}_{cps}\"\n",
    "rdf_dict = {'config' : {'bioimageio' : {'nickname' : nickname}}}\n",
    "rdf_dict['config']['bioimageio']['nickname']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "novel-designer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
